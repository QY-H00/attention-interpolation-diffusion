{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (P)AID: (Prompt-guided) Attention Interpolation of Text-to-Image Diffusion\n",
    "\n",
    "Author: Qiyuan He $^1$ Jinghao Wang $^2$ Ziwei Liu $^2$ Angela Yao $^1$\n",
    "\n",
    "$^1$ National University of Singapore \n",
    "\n",
    "$^2$ S-Lab, Nanyang Technological University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, lpips\n",
    "from utils import show_images_horizontally, compute_smoothness_and_consistency\n",
    "from pipeline_interpolated_stable_diffusion import InterpolationStableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = InterpolationStableDiffusionPipeline(\n",
    "    repo_name=\"runwayml/stable-diffusion-v1-5\",\n",
    "    guidance_scale=10.0,\n",
    "    scheduler_name=\"unipc\",\n",
    ")\n",
    "\n",
    "# Initialize the generator\n",
    "vae_scale_factor = 8\n",
    "channel = pipe.unet.config.in_channels\n",
    "height = pipe.unet.config.sample_size * vae_scale_factor\n",
    "width = pipe.unet.config.sample_size * vae_scale_factor\n",
    "torch_device = \"cuda\"\n",
    "generator = torch.cuda.manual_seed(1002)\n",
    "\n",
    "latent = torch.randn(\n",
    "    (1, channel, height // vae_scale_factor, width // vae_scale_factor),\n",
    "    generator=generator,\n",
    "    device=torch_device,\n",
    ")\n",
    "\n",
    "num_inference_steps = 50\n",
    "lpips_model = lpips.LPIPS(net=\"vgg\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: if you have sufficient computational resources (GPU Memory), you can change the below `pipe.interpolate_save_gpu` which generates the images one by one to `pipe.interpolate` which generates all interpolation images at once.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 6.1 / 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a dog driving a car, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 6\n",
    "beta = 3\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, interact=True)\n",
    "smoothness, consistency, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness, consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 8.1 / 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a toy named dog-car, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 8\n",
    "beta = 8\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, prompt1=\"a dog\", prompt2=\"a car\", interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 8.1 / 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a car with furry texture, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 8\n",
    "beta = 8\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, prompt1=\"a dog\", prompt2=\"a car\", interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 1.0\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a car with dog head, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 29.75\n",
    "beta = 20\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, prompt1=\"a dog\", prompt2=\"a car\", interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 20.1 / 50\n",
    "num_inference_steps = 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A product display of toy named Gundam-Pikachu, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A product display of toy named Pikachu, Pokemon created by Game Freak and Nitendo, best quality, extremely detailed\"\n",
    "prompt2 = \"A product display of toy named Gundam, Mobile Suit Gundam Figure Gundam Universe, Bandai Tamashii Nations, best quality, extremely detailed\"\n",
    "\n",
    "alpha = 6\n",
    "beta = 2\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=7,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AID",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
