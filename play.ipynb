{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAID: (Prompt-guided) Attention Interpolation of Text-to-Image Diffusion\n",
    "\n",
    "Author: Qiyuan He $^1$ Jinghao Wang $^2$ Ziwei Liu $^2$ Angela Yao $^1$\n",
    "\n",
    "$^1$ National University of Singapore \n",
    "\n",
    "$^2$ S-Lab, Nanyang Technological University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SD1.5-512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, lpips\n",
    "from utils import show_images_horizontally, compute_smoothness_and_consistency\n",
    "from pipeline_interpolated_stable_diffusion import InterpolationStableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = InterpolationStableDiffusionPipeline(\n",
    "    repo_name=\"runwayml/stable-diffusion-v1-5\",\n",
    "    guidance_scale=10.0,\n",
    "    scheduler_name=\"unipc\",\n",
    ")\n",
    "\n",
    "# Initialize the generator\n",
    "vae_scale_factor = 8\n",
    "channel = pipe.unet.config.in_channels\n",
    "height = pipe.unet.config.sample_size * vae_scale_factor\n",
    "width = pipe.unet.config.sample_size * vae_scale_factor\n",
    "torch_device = \"cuda\"\n",
    "generator = torch.cuda.manual_seed(1002)\n",
    "\n",
    "latent = torch.randn(\n",
    "    (1, channel, height // vae_scale_factor, width // vae_scale_factor),\n",
    "    generator=generator,\n",
    "    device=torch_device,\n",
    ")\n",
    "pipe.to(torch_device)\n",
    "num_inference_steps = 50\n",
    "lpips_model = lpips.LPIPS(net=\"vgg\").to(torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: if you have sufficient GPU Memory, you can change the below `pipe.interpolate_save_gpu` which generates the images one by one to `pipe.interpolate` which generates all interpolation images at once.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 6.1 / 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a dog driving a car, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 6\n",
    "beta = 3\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, interact=True)\n",
    "smoothness, consistency, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness, consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 8.1 / 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a toy named dog-car, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 8\n",
    "beta = 8\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, prompt1=\"a dog\", prompt2=\"a car\", interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 8.1 / 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a car with furry texture, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 8\n",
    "beta = 8\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, prompt1=\"a dog\", prompt2=\"a car\", interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 1.0\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A photo of a car with dog head, logical, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A photo of dog, best quality, extremely detailed\"\n",
    "prompt2 = \"A photo of car, best quality, extremely detailed\"\n",
    "alpha = 29.75\n",
    "beta = 20\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=3,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, prompt1=\"a dog\", prompt2=\"a car\", interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_ratio = 20.1 / 50\n",
    "num_inference_steps = 50\n",
    "early = \"fused_inner\"\n",
    "late = \"self\"\n",
    "guide_prompt = (\n",
    "    \"A product display of toy named Gundam-Pikachu, best quality, extremely detailed\"\n",
    ")\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "\n",
    "prompt1 = \"A product display of toy named Pikachu, Pokemon created by Game Freak and Nitendo, best quality, extremely detailed\"\n",
    "prompt2 = \"A product display of toy named Gundam, Mobile Suit Gundam Figure Gundam Universe, Bandai Tamashii Nations, best quality, extremely detailed\"\n",
    "\n",
    "alpha = 6\n",
    "beta = 2\n",
    "images = pipe.interpolate_save_gpu(\n",
    "    latent,\n",
    "    latent,\n",
    "    prompt1,\n",
    "    prompt2,\n",
    "    guide_prompt=guide_prompt,\n",
    "    size=7,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    early=early,\n",
    "    late=late,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    negative_prompt=negative_prompt,\n",
    ")\n",
    "show_images_horizontally(images, interact=True)\n",
    "smoothness, _, _ = compute_smoothness_and_consistency(images, lpips_model)\n",
    "print(smoothness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDXL-1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "from utils import show_images_horizontally\n",
    "from prior import generate_beta_tensor\n",
    "from pipeline_interpolated_sdxl import InterpolatedStableDiffusionXLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_pipe = InterpolatedStableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "generator = torch.cuda.manual_seed(1002)\n",
    "dtype = torch.float16\n",
    "size = xl_pipe.default_sample_size\n",
    "latent_start = torch.randn(\n",
    "    1,\n",
    "    xl_pipe.unet.config.in_channels,\n",
    "    size,\n",
    "    size,\n",
    "    dtype=dtype,\n",
    "    generator=generator,\n",
    ")\n",
    "latent_end = torch.randn(\n",
    "    1,\n",
    "    xl_pipe.unet.config.in_channels,\n",
    "    size,\n",
    "    size,\n",
    "    dtype=dtype,\n",
    "    generator=generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_a = \"a Pikachu, pokemon created by Game Freak\"\n",
    "prompt_b = \"a Eevee, pokemon created by Game Freak\"\n",
    "interpolation_size = 7\n",
    "sequence_coefficients = generate_beta_tensor(interpolation_size).to(\n",
    "    dtype=dtype, device=\"cuda\"\n",
    ")\n",
    "sequence_coefficients = sequence_coefficients[1:-1]\n",
    "print(sequence_coefficients)\n",
    "results = []\n",
    "for i in range(interpolation_size-2):\n",
    "    images = xl_pipe.interpolate_save_gpu(\n",
    "        sequence_coefficients[i],\n",
    "        prompt_start=prompt_a,\n",
    "        prompt_end=prompt_b,\n",
    "        latent_start=latent_start,\n",
    "        latent_end=latent_end,\n",
    "        early=\"fused_outer\",\n",
    "        num_inference_steps=50,\n",
    "        output_type=\"np\",\n",
    "    )\n",
    "    if i == 0:\n",
    "        results.append(images.images[0])\n",
    "        continue\n",
    "    if i == interpolation_size - 3:\n",
    "        results.append(images.images[1])\n",
    "        results.append(images.images[-1])\n",
    "        break\n",
    "    results.append(images.images[1])\n",
    "show_images_horizontally(results, interact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AID",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
